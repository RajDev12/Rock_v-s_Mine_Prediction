# -*- coding: utf-8 -*-
"""Rock/Mine prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dfyTwSEMTwbznbEqB7F2QFzOALT0_4iC

Importing the dependencies
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

"""Data Collection and Preprocessing

"""

# Loading the dataset into pandas dataframe

df=pd.read_csv('/content/Copy of sonar data.csv',header=None)

df.head()

#Number of Row and columns in the dataset
df.shape

#Statistical measures of the dataframe
df.describe()

#we cant find statistical measure for the categorical value which is present inside our 61th column

#The value counts of the targete variable .i.e  61th column
df[60].value_counts()
#here M=Mine and R=Rock

#  the DataFrame df, splits it into groups based on the unique values in column 60, and then calculates the mean of all numerical columns separately for each of those groups.
df.groupby(60).mean()

#Spliting the data into input and target variable
#We use axis 1 for the column and 0 for the rows
X=df.drop(columns=60, axis=1)
Y=df[60]

print(X.shape)
print(Y.shape)



"""Splitting the dataset into train and test"""

X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.1,stratify=Y, random_state=1)

"""#stratify=Y ensures that the class distribution (for classification problems) or target variable distribution (for regression problems) is approximately preserved in both the training and test sets. This is important to avoid potential data leakage or biased results. **bold text**
###Random state 1 sets a seed value for the random number generator, which ensures reproducibility of the split. If you run the code multiple times with the same random_state, you will get the same split of the data.
"""

print(X.shape, X_train.shape, X_test.shape)

"""Importing dependencies for model"""

from sklearn.linear_model import LogisticRegression

model=LogisticRegression()

#training the logistic regression model with training data
model.fit(X_train, Y_train)



"""# Evaluating our MOdel"""

from sklearn.metrics import accuracy_score

#Accuracy on training data
X_train_prediction=model.predict(X_train)
training_accuracy=accuracy_score(X_train_prediction,Y_train)
print(training_accuracy)

X_test_preed=model.predict(X_test)
test_accuracy=accuracy_score(X_test_preed,Y_test)

print(test_accuracy)
print(X_test_preed)

input_data=(0.0200,0.0371,0.0428,0.0207,0.0954,0.0986,0.1539,0.1601,0.3109,0.2111,0.1609,0.1582,0.2238,0.0645,0.0660,0.2273,0.3100,0.2999,0.5078,0.4797,0.5783,0.5071,0.4328,0.5550,0.6711,0.6415,0.7104,0.8080,0.6791,0.3857,0.1307,0.2604,0.5121,0.7547,0.8537,0.8507,0.6692,0.6097,0.4943,0.2744,0.0510,0.2834,0.2825,0.4256,0.2641,0.1386,0.1051,0.1343,0.0383,0.0324,0.0232,0.0027,0.0065,0.0159,0.0072,0.0167,0.0180,0.0084,0.0090,0.0032)
#input data is a list
#convert the list into np array
input_data_as_nparray=np.asarray(input_data)

#reshape the np array as we are predicting for a single instance
input_data_reshaped=input_data_as_nparray.reshape(1,-1)

prediction=model.predict(input_data_reshaped)
print(prediction)

#
if(prediction=='R'):
  print("Rock")
else:
  print("Mine")